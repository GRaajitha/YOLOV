{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480dbdd-2443-4350-be57-bec4bca9c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "#provide path to annotation directory containing coco jsons\n",
    "annotation_dir = \"/shared/vision/dataset/metadata/v8/v3.0onwards_8_cls_70_30split_06_27_15_05/\"\n",
    "train_file = \"extended_train_annotations_coco_fmt.json\"\n",
    "val_file = \"val_annotations_coco_fmt.json\"\n",
    "test_file = \"test_annotations_coco_fmt.json\"\n",
    "\n",
    "annotations = []\n",
    "images = []\n",
    "videos = []\n",
    "def load_annotations(dir, file):\n",
    "    file_path = os.path.join ( dir, file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        la = len(data[\"annotations\"])\n",
    "        li = len(data[\"images\"])\n",
    "        lv = 0\n",
    "        annotations.extend(data[\"annotations\"])\n",
    "        images.extend(data[\"images\"])\n",
    "        if \"videos\" in data:\n",
    "            videos.extend(data[\"videos\"])\n",
    "            lv = len(data[\"videos\"])\n",
    "        print(f\"file {file} has {lv} videos {li} images and {la} instances\")\n",
    "        return data\n",
    "\n",
    "train_data = load_annotations(annotation_dir, train_file)\n",
    "val_data = load_annotations(annotation_dir, val_file)\n",
    "test_data = load_annotations(annotation_dir, test_file)\n",
    "\n",
    "print(f\"total number of {len(videos)} videos {len(images)} images {len(annotations)} annotations: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff54560-8473-4415-bce5-2e05096a3545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "vid_lengths = Counter([vid[\"length\"] for vid in test_data[\"videos\"]])\n",
    "print(OrderedDict(vid_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fcc2b0-2e05-49ce-b624-cea21bc025c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def normalize_key(value):\n",
    "    if isinstance(value, list):\n",
    "        parts = [str(v) for v in value]\n",
    "    else:\n",
    "        parts = str(value).replace('[', '').replace(']', '').replace(\"'\", \"\").split('_')\n",
    "    parts = [p.strip() for p in parts if p.strip()]\n",
    "    return '_'.join(sorted(parts)) if parts else 'unavailable'\n",
    "\n",
    "assert len(annotations) > 0, \"no annotations found\"\n",
    "attributes = [\"class_name\", \"size_cat\", \"horizon\", \"occlusion\", \"clipping\", \"primary_terrain\", \"secondary_terrain\", \"terrain_modifier\", \"low_visibility\", \"annotated_weather\", \"cloud_coverage\", \"intruder_lateral_view\", \"intruder_vertical_view\", \"image_quality\"]\n",
    "\n",
    "plots_per_fig = 16\n",
    "rows, cols = 4, 4\n",
    "plot_count = 0\n",
    "fig = None\n",
    "axes = None\n",
    "\n",
    "for idx, attr in enumerate(attributes):\n",
    "    print(f\"\\n\\ndistribution of {attr}:\")\n",
    "    dist = defaultdict(int)\n",
    "\n",
    "    for annot in annotations:\n",
    "        value = annot[\"attributes\"].get(attr, 'unavailable')\n",
    "        normalized = normalize_key(value)\n",
    "        dist[normalized] += 1\n",
    "\n",
    "    for key, val in dist.items():\n",
    "        print(f\"{key}: {val}, \", end=' ')\n",
    "    print()  # new line after all values printed\n",
    "\n",
    "    if plot_count % plots_per_fig == 0:\n",
    "        if fig:\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(20, 20))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    ax = axes[plot_count % plots_per_fig]\n",
    "    bars = ax.bar(dist.keys(), dist.values(), width=0.9)\n",
    "    ax.set_title(str(attr))\n",
    "    ax.set_ylabel(\"number of instances\")\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    ax.bar_label(bars)\n",
    "\n",
    "    plot_count += 1\n",
    "\n",
    "# Show the last figure\n",
    "if fig:\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac96ea4-eebc-4f85-8716-0e98b649dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def normalize_key(value):\n",
    "    if isinstance(value, list):\n",
    "        parts = [str(v) for v in value]\n",
    "    else:\n",
    "        parts = str(value).replace('[', '').replace(']', '').replace(\"'\", \"\").split('_')\n",
    "    parts = [p.strip() for p in parts if p.strip()]\n",
    "    return '_'.join(sorted(parts)) if parts else 'unavailable'\n",
    "\n",
    "assert len(annotations) > 0, \"no annotations found\"\n",
    "attributes = [\"class_name\", \"size_cat\", \"horizon\", \"occlusion\", \"clipping\", \"annotated_weather\", \"cloud_coverage\", \n",
    "              \"intruder_lateral_view\", \"intruder_vertical_view\"]\n",
    "\n",
    "plots_per_fig = 8\n",
    "rows, cols = 4, 2\n",
    "plot_count = 0\n",
    "fig = None\n",
    "axes = None\n",
    "\n",
    "for idx, attr in enumerate(attributes):\n",
    "    print(f\"\\n\\ndistribution of {attr} (with class_name breakdown):\")\n",
    "    \n",
    "    # For class breakdown: attr_value -> class_name -> count\n",
    "    dist = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for annot in annotations:\n",
    "        attr_val = normalize_key(annot[\"attributes\"].get(attr, 'unavailable'))\n",
    "        class_val = normalize_key(annot[\"attributes\"].get(\"class_name\", 'unavailable'))\n",
    "        dist[attr_val][class_val] += 1\n",
    "\n",
    "    # Print distribution\n",
    "    for attr_val, class_counts in dist.items():\n",
    "        print(f\"{attr_val}: \", end='')\n",
    "        for cls, count in class_counts.items():\n",
    "            print(f\"{cls}: {count}, \", end='')\n",
    "        print()\n",
    "\n",
    "    # Plotting (skip for class_name itself since it would be redundant)\n",
    "    if attr != \"class_name\":\n",
    "        if plot_count % plots_per_fig == 0:\n",
    "            if fig:\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            fig, axes = plt.subplots(rows, cols, figsize=(20, 20))\n",
    "            axes = axes.flatten()\n",
    "\n",
    "        ax = axes[plot_count % plots_per_fig]\n",
    "\n",
    "        attr_values = list(dist.keys())\n",
    "        class_names = sorted({cls for counts in dist.values() for cls in counts})\n",
    "        bar_width = 0.8 / len(class_names)  # width of each bar per class\n",
    "\n",
    "        for i, cls in enumerate(class_names):\n",
    "            counts = [dist[val].get(cls, 0) for val in attr_values]\n",
    "            ax.bar(\n",
    "                [x + i * bar_width for x in range(len(attr_values))],\n",
    "                counts,\n",
    "                bar_width,\n",
    "                label=cls\n",
    "            )\n",
    "\n",
    "        ax.set_title(str(attr))\n",
    "        ax.set_ylabel(\"number of instances\")\n",
    "        ax.set_xticks([x + bar_width * len(class_names) / 2 for x in range(len(attr_values))])\n",
    "        ax.set_xticklabels(attr_values, rotation=90)\n",
    "        ax.legend(fontsize='small')\n",
    "        \n",
    "        plot_count += 1\n",
    "\n",
    "# Show the last figure\n",
    "if fig:\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c71a9-aaab-472e-be03-8a5fb324d62a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define colors for visualization\n",
    "random.seed(42)\n",
    "COLORS = {i: (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) for i in range(16)}\n",
    "\n",
    "# Load ground truth and prediction data\n",
    "with open(\"/home/rgummadi/YOLOV/gt_refined.json\", \"r\") as f:\n",
    "    gt_data = json.load(f)\n",
    "\n",
    "with open(\"/home/rgummadi/YOLOV/refined_pred.json\", \"r\") as f:\n",
    "    pred_data = json.load(f)\n",
    "\n",
    "# Mapping of category IDs to class names\n",
    "category_mapping = {c[\"id\"]: c[\"name\"] for c in gt_data[\"categories\"]}\n",
    "\n",
    "# Load images into a dictionary for easy access\n",
    "image_mapping = {img[\"id\"]: img[\"file_name\"] for img in gt_data[\"images\"]}\n",
    "\n",
    "# Prediction confidence threshold\n",
    "CONF_THRESH = 0.1\n",
    "\n",
    "# Function to draw bounding boxes\n",
    "def draw_boxes(image, annotations, color, label_prefix=\"GT\", is_prediction=False):\n",
    "    for ann in annotations:\n",
    "        if is_prediction and ann[\"score\"] < CONF_THRESH:\n",
    "            continue  # Skip low-confidence predictions\n",
    "\n",
    "        x, y, w, h = map(int, ann[\"bbox\"])\n",
    "        category_id = ann[\"category_id\"]\n",
    "        class_name = category_mapping.get(category_id, \"Unknown\")\n",
    "        label = f\"{label_prefix}: {class_name}\"\n",
    "\n",
    "        # Add score to prediction labels\n",
    "        if is_prediction:\n",
    "            label += f\" ({ann['score']:.2f})\"\n",
    "\n",
    "        # Draw rectangle and label\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(image, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "# Create an output directory\n",
    "os.makedirs(\"output_visualization\", exist_ok=True)\n",
    "\n",
    "# Process each image\n",
    "for image_id, image_name in image_mapping.items():\n",
    "    # Load image\n",
    "    if not os.path.exists(image_name):\n",
    "        continue  # Skip if image is missing\n",
    "\n",
    "    image = cv2.imread(image_name)\n",
    "\n",
    "    # Get GT annotations\n",
    "    gt_annotations = [ann for ann in gt_data[\"annotations\"] if ann[\"image_id\"] == image_id]\n",
    "    \n",
    "    # Get Prediction annotations (filtered by confidence threshold)\n",
    "    pred_annotations = [ann for ann in pred_data if ann[\"image_id\"] == image_id and ann[\"score\"] >= CONF_THRESH]\n",
    "\n",
    "    # Draw GT and prediction boxes\n",
    "    draw_boxes(image, gt_annotations, (0, 255, 0), \"GT\")  # Green for GT\n",
    "    draw_boxes(image, pred_annotations, (0, 0, 255), \"Pred\", is_prediction=True)  # Red for predictions\n",
    "\n",
    "    # Save or show the image\n",
    "    output_path = os.path.join(\"output_visualization\", os.path.basename(image_name))\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "    # Optional: Show image (comment this out if running on a server)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(image_name)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
